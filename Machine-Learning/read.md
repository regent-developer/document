# Machine-Learning

## 21 句话入门机器学习

- 机器学习有四种用途：分类、聚类、回归和降维。

- 分类和聚类都是对个体样本归类，看起来很相似，实则相去甚远——前者属于有监督的学习，后者属于无监督的学习。

  - 分类是基于经验的，而经验来自过往的数据，这意味着分类需要训练；聚类则是基于当前全部样本的特征，不依赖经验，自然也就无需训练。

- 从字面上看，分类和回归看上去风马牛不相及，其实二者是亲兄弟，使用的算法几乎完全重合。

  - 分类是对个体样本做出定性判定，回归是对个体样本做出定量判定，二者同属于有监督的学习，都是基于经验的。

- 传统的软件开发，代码是重点，而对于机器学习，数据是重点。

  - 在训练机器学习模型时，数据的质量和数量都会影响训练结果的准确性和有效性。因此，无论是学习还是应用机器学习模型解决问题，前提都是要有足够多且足够好的数据集。

- 数据集通常是指由若干个样本数据组成的二维数组，数组的每一行表示一个样本的数据。

- 数据集的列，也被成为特征维或特征列。

- 所谓降维，并非是将数据集从二维变成一维，而是减少数据集的特征维。

- 标准化是对样本集的每个特征列减去该特征列的平均值进行中心化，再除以标准差进行缩放。

- 归一化是对样本集的每个特征列减去该特征列的最小值进行中心化，再除以极差（最大值最小值之差）进行缩放。

  - 归一化处理类似于标准化，结果收敛于[0,1]区间内。

- 机器学习模型只能处理数值数据，因此需要将性别、职业等非数值数据变成整数，这个过程被称为特征编码。

- Scikit-learn 的数据集子模块 datasets 提供了若干数据集：函数名以 load 开头的是模块内置的小型数据集；函数名以 fetch 开头，是需要从外部数据源下载的大型数据集。

  - datasets.load_boston([return_X_y]) ：加载波士顿房价数据集
  - datasets.load_breast_cancer([return_X_y]) ：加载威斯康星州乳腺癌数据集
  - datasets.load_diabetes([return_X_y]) ：加载糖尿病数据集
  - datasets.load_digits([n_class, return_X_y]) ：加载数字数据集
  - datasets.load_iris([return_X_y]) ：加载鸢尾花数据集。
  - datasets.load_linnerud([return_X_y]) ：加载体能训练数据集
  - datasets.load_wine([return_X_y]) ：加载葡萄酒数据集
  - datasets.fetch_20newsgroups([data_home, …]) ：加载新闻文本分类数据集
  - datasets.fetch_20newsgroups_vectorized([…]) ：加载新闻文本向量化数据集
  - datasets.fetch_california_housing([…]) ：加载加利福尼亚住房数据集
  - datasets.fetch_covtype([data_home, …]) ：加载森林植被数据集
  - datasets.fetch_kddcup99([subset, data_home, …]) ：加载网络入侵检测数据集
  - datasets.fetch_lfw_pairs([subset, …]) ：加载人脸（成对）数据集
  - datasets.fetch_lfw_people([data_home, …]) ：加载人脸（带标签）数据集
  - datasets.fetch_olivetti_faces([data_home, …]) ：加载 Olivetti 人脸数据集
  - datasets.fetch_rcv1([data_home, subset, …])：加载路透社英文新闻文本分类数据集
  - datasets.fetch_species_distributions([…]) ：加载物种分布数据集

- 每个二维的数据集对应着一个一维的标签集，用于标识每个样本的所属类别或属性值。通常数据集用大写字母 X 表示，标签集用小写字母 y 表示。

- 模型训练时，通常会将数据集和标签集分成两部分：一部分用于训练，一部分用于测试。

- 近朱者赤，近墨者黑，距离谁最近，就和谁同类——这就是 k-近邻分类。

- 一辆开了八年的大切诺基可以卖多少钱？最简单的方法是参考 k 辆同款车型且使用年限相近的二手车售价的均值——这就是 k-近邻回归。

- 常用的回归模型的评价方法有均方误差、中位数绝对误差和复相关系数等。

- 决策树、支持向量机（SVM）、贝叶斯等算法，既可以解决分类问题，也可以解决回归问题。

- 随机森林是将多棵分类决策树或者回归决策树集成在一起的算法，是机器学习的一个分支——集成学习的方法。

- 基于质心的聚类，无论是 k 均值聚类还是均值漂移聚类，其局限性都是显而易见的：无法处理细长条、环形或者交叉的不规则的样本分布。

- 基于密度的空间聚类具有更好的适应性，可以发现任何形状的簇。

- 主成分分析（PCA）是一种统计方法，也是最常用的降维方法。

https://xufive.blog.csdn.net/article/details/117291777?spm=1000.2115.3001.4373
