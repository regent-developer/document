# 张量

## 张量的基本概念

PyTorch 是一个 Python 深度学习框架，它将数据封装成张量（Tensor）来进行运算。PyTorch 中的张量就是元素为同一种数据类型的多维矩阵。在 PyTorch 中，张量以 "类" 的形式封装起来，对张量的一些运算、处理的方法被封装在类中。

## 张量的创建

### 基本创建方式
* torch.tensor 根据指定数据创建张量
* torch.Tensor 根据形状创建张量, 其也可用来创建指定数据的张量
* torch.IntTensor、torch.FloatTensor、torch.DoubleTensor 创建指定类型的张量

```python
import torch
import numpy as np
import random

# 根据已有数据创建张量
# 创建张量标量
data = torch.tensor(10)

# 使用numpy数组创建张量
data = np.random.randn(2, 3)
data = torch.tensor(data)

# 使用列表创建张量
data = [[10., 20., 30.], [40., 50., 60.]]
data = torch.tensor(data)

# 创建指定形状的张量
# 创建2行3列的张量, 默认 dtype 为 float32
data = torch.Tensor(2, 3)

# 则创建包含指定元素（列表）的张量
data = torch.Tensor([10])
data = torch.Tensor([10, 20])

# 使用具体类型的张量
# 创建2行3列张量（dtype 为 int32 的张量）
data = torch.IntTensor(2, 3)

# 如果传递的元素类型不正确, 则会进行类型转换
data = torch.IntTensor([2.5, 3.3])

data = torch.ShortTensor()  # int16
data = torch.LongTensor()   # int64
data = torch.FloatTensor()  # float32
data = torch.DoubleTensor() # float64
```

### 创建线性和随机张量
* torch.arange 和 torch.linspace 创建线性张量
* torch.random.init_seed 和 torch.random.manual_seed 随机种子设置
* torch.randn 创建随机张量

```python
import torch

# 在指定区间按照步长生成元素 (start, end, step)
data = torch.arange(0, 10, 2)

# 在指定区间按照元素个数生成
data = torch.linspace(0, 11, 10)

# 创建随机张量
data = torch.randn(2, 3)  # 创建2行3列张量

# 随机数种子设置
print('随机数种子:', torch.random.initial_seed())
torch.random.manual_seed(100) # 设置随机种子
print('随机数种子:', torch.random.initial_seed())

```



### 创建01张量

* torch.ones 和 torch.ones_like 创建全1张量

* torch.zeros 和 torch.zeros_like 创建全0张量

* torch.full 和 torch.full_like 创建全为指定值张量

```python
import torch

# 创建指定形状全0张量
data = torch.zeros(2, 3)

# 根据张量形状创建全0张量
data = torch.zeros_like(data)

# 创建指定形状全0张量
data = torch.ones(2, 3)

# 根据张量形状创建全1张量
data = torch.ones_like(data)

# 创建指定形状指定值的张量
data = torch.full([2, 3], 10)

# 根据张量形状创建指定值的张量
data = torch.full_like(data, 20)
```



### 张量元素类型转换

* tensor.type(torch.DoubleTensor)
* tensor.type(torch.ShortTensor)
* tensor.type(torch.IntTensor)
* tensor.type(torch.LongTensor)
* tensor.type(torch.FloatTensor)

* torch.double()
* torch.short()
* torch.int()
* torch.long()
* torch.float()

```python
import torch

data = torch.randn(2, 3)
print(data.dtype)

data = data.type(torch.DoubleTensor)
print(data.dtype)
data = data.type(torch.ShortTensor)
print(data.dtype)
data = data.type(torch.IntTensor)
print(data.dtype)
data = data.type(torch.FloatTensor)
print(data.dtype)
data = data.type(torch.LongTensor)
print(data.dtype)

data = data.double()
print(data.dtype)
data = data.short()
print(data.dtype)
data = data.int()
print(data.dtype)
data = data.long()
print(data.dtype)
data = data.float()
print(data.dtype)
```



## 张量的数值计算



### 张量基本运算

* add
* sub
* mul
* div
* neg
* add_
* sub_
* mul_
* div_
* neg_

**Torch里面所有带"_"的操作，都是in-place的，修改原数据。比如x.add_(y)，x+y的结果会存储到原来的x中。**

```python
import torch
import numpy as np

data = torch.randint(0, 10, [2, 3])
print(data)

# 不修改原数据
new_data = data.add(10) 
print(new_data)
print(data)

# 修改原数据
data.add_(10) 
print(data)
```



### 阿达玛积

阿达玛积指的是矩阵对应位置的元素相乘。

```python
import torch

data1 = torch.tensor([[1, 2], [3, 4]])
data2 = torch.tensor([[5, 6], [7, 8]])

# 方法一
data = torch.mul(data1, data2)

# 方法二
data = data1.mul(data2)

# 方法三
data = data1 * data2

```



### 点积运算

点积运算要求第一个矩阵 shape: (n, m)，第二个矩阵 shape: (m, p), 两个矩阵点积运算 shape 为: (n, p)。

* 运算符 @ 用于进行两个矩阵的点乘运算
* torch.mm 用于进行两个矩阵点乘运算, 要求输入的矩阵为2维
* torch.bmm 用于批量进行矩阵点乘运算, 要求输入的矩阵为3维
* torch.matmul 对进行点乘运算的两矩阵形状没有限定
  * 对于输入都是二维的张量相当于 mm 运算
  * 对于输入都是三维的张量相当于 bmm 运算
  * 对数输入的 shape 不同的张量, 对应的最后几个维度必须符合矩阵运算规则



```python
import torch

data1 = torch.tensor([1, 2], [2, 3], [3, 4])
data2 = torch.tensor([1, 2], [2, 3])

# 方法一
data = data1 @ data2

# 方法二
data = torch.mm(data1, data2)

# 方法三
data = torch.matmul(data1, data2)

# troch.bmm
data1 = torch.randn(3, 4, 5)
data2 = torch.randn(3, 5, 8)

data = torch.bmm(data1, data2)
```



### 指定运算设备

PyTorch 默认会将张量创建在 CPU 控制的内存中, 即: 默认的运算设备为 CPU。我们也可以将张量创建在 GPU 上, 能够利用对于矩阵计算的优势加快模型训练。

将张量移动到 GPU 上的方法:

* 使用 cuda 方法
* 直接在 GPU 上创建张量
* 使用 to 方法指定设备

```python
import torch

# 使用cuda方法
data = torch.tensor([10, 20 ,30])
print('存储设备：', data.device)

# 如果安装的不是GPU版的pytorch或者没有NVIDIA显卡的话，会报错
data = data.cuda()
print('存储设备:', data.device)

data = data.cpu()
print('存储设备:', data.device)
    
# 直接在GPU上创建张量
data = torch.tensor([10, 20, 30], device='cuda:0')
print('存储设备:', data.device)

## 使用cpu函数将张量移动到 cpu 上
data = data.cpu()
print('存储设备:', data.device)
    
# 使用to方法指定设备
data = torch.tensor([10, 20, 30])
print('存储设备:', data.device)

data = data.to('cuda:0')
print('存储设备:', data.device)

# 存储在不同设备的张量不能运算

data1 = torch.tensor([10, 20, 30], device='cuda:0')
data2 = torch.tensor([10, 20, 30])
print(data1.device, data2.device)

data = data1 + data2
print(data)
```



## 张量的类型转换



### 张量转换为numpy数组

使用 tensor.numpy 函数可以将张量转换为 ndarray 数组，但是是共享内存，可以使用 copy 函数避免共享。

```python
import torch

# 使用张量对象中numpy函数进行转换
data_tensor = torch.tensor([2, 3, 4])
data_numpy = data_tensor.numpy()
print('使用张量对象中numpy函数进行转换')
print(data_tensor)
print(data_numpy)

# 修改转换后数组，原数据改变
print('修改转换后数组，原数据改变')
data_numpy[0] = 100
print(data_tensor)
print(data_numpy)

# 使用copy函数进行转换拷贝
data_copy = torch.tensor([2, 3, 4])
data_copy.copy_(data_tensor)

data_numpy  = data_copy.numpy()
print('使用copy函数进行转换拷贝')
print(data_tensor)
print(data_numpy)

# 修改转换后数组，原数据不变
print('修改转换后数组，原数据不变')
data_numpy[0] = 1
print(data_tensor)
print(data_numpy)
```



### numpy数组转化为张量

* 使用 from_numpy 可以将 ndarray 数组转换为 Tensor，默认共享内存，使用 copy 函数避免共享。

* 使用 torch.tensor 可以将 ndarray 数组转换为 Tensor，默认不共享内存。

```python
import torch
import numpy as np

# 使用 from_numpy 函数
data_numpy = np.array([2, 3, 4])

# 浅拷贝
data_tensor = torch.from_numpy(data_numpy)
print(data_tensor)

# 深拷贝
data_copy.copy_(data_numpy)
data_tensor = torch.from_numpy(data_copy)
print(data_tensor)

# 使用 torch.tensor 函数
data_tensor = torch.tensor(data_numpy)
print(data_tensor)
```

### 标量张量和数字的转换

对于只有一个元素的张量，使用 item 方法将该值从张量中提取出来

```python
import torch

# 当张量只包含一个元素时, 可以通过 item 函数提取出该值
data = torch.tensor([10,])
print(data.item())

data = torch.tensor(10)
print(data.item())
```



## 张量拼接

### torch.cat 函数的使用

torch.cat 函数可以将两个张量根据指定的维度拼接起来

```python
import torch

data1 = torch.randint(0, 10, [3, 5, 4])
data2 = torch.randint(0, 10, [3, 5, 4])

# 按0维度拼接
new_data = torch.cat([data1, data2], dim=0)
print(new_data.shape)

# 按1维度拼接
new_data = torch.cat([data1, data2], dim=1)
print(new_data.shape)

# 按2维度拼接
new_data = torch.cat([data1, data2], dim=2)
print(new_data.shape)   

```



### torch.stack 函数的使用

torch.stack 函数可以将两个张量根据指定的维度叠加起来

把多个2维的张量凑成一个3维的张量；多个3维的凑成一个4维的张量…以此类推，也就是在**增加新的维度进行堆叠**



```python
import torch

data1= torch.randint(0, 10, [2, 3])
data2= torch.randint(0, 10, [2, 3])
print(data1)
print(data2)

# 按0维度叠加
new_data = torch.stack([data1, data2], dim=0)
print(new_data.shape)

# 按1维度叠加
new_data = torch.stack([data1, data2], dim=1)
print(new_data.shape)

# 按2维度叠加
new_data = torch.stack([data1, data2], dim=2)
print(new_data.shape)
```



## 张量索引

### 简单行列索引

```python
import torch

data = torch.randint(0, 10, [4, 5])
print(data)

# 简单行索引
print(data[0])

# 简单列索引
print(data[:, 0])
```

### 列表索引

```python
import torch

data = torch.randint(0, 10, [4, 5,3])
print(data)

# 维度需保持一致，否则报错（IndexError: too many indices for tensor of dimension n）
print(data[[0,1], [1,1], [2,2]])

print(data[[0], [:,1], [2]])
```

